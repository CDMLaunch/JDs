{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import pyLDAvis\n",
    "sns.set()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import gensim\n",
    "\n",
    "\n",
    "# import nltk\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5379 entries, 0 to 5378\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Description         5379 non-null   object\n",
      " 1   lower_description   5379 non-null   object\n",
      " 2   word_tokenized      5379 non-null   object\n",
      " 3   sentence_tokenized  5379 non-null   object\n",
      " 4   word_count          5379 non-null   int64 \n",
      " 5   sentence_count      5379 non-null   int64 \n",
      " 6   clean_words         5379 non-null   object\n",
      " 7   clean_stemmed       5379 non-null   object\n",
      " 8   clean_lemmed        5379 non-null   object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 378.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('df_description_processed.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('business', 14210),\n",
       " ('analysis', 9052),\n",
       " ('skill', 8872),\n",
       " ('analytics', 8459),\n",
       " ('ability', 8236),\n",
       " ('science', 7638),\n",
       " ('solution', 7225),\n",
       " ('learning', 7205),\n",
       " ('technology', 6725),\n",
       " ('development', 6163)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the transform\n",
    "vectorizer = CountVectorizer(stop_words = 'english', max_df = 0.75)\n",
    "# tokenize and build vocab\n",
    "bag_of_words = vectorizer.fit_transform(df.clean_lemmed)\n",
    "# summarize\n",
    "sum_words = bag_of_words.sum(axis=0) \n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "words_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5379x18641 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 899940 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5379 documents represented as a 14,409 dimensional vector (14,409 words)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=5, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA.fit(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = LDA.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15594, 16104,  1515, 13446, 11054,  1503,  2910, 10359, 15081,\n",
       "        9969], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topic_words = first_topic.argsort()[-10:]\n",
    "top_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skill\n",
      "statistical\n",
      "analytics\n",
      "product\n",
      "model\n",
      "analysis\n",
      "business\n",
      "machine\n",
      "science\n",
      "learning\n"
     ]
    }
   ],
   "source": [
    "for i in top_topic_words:\n",
    "    print(vectorizer.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['skill', 'statistical', 'analytics', 'product', 'model', 'analysis', 'business', 'machine', 'science', 'learning']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['process', 'report', 'analytics', 'support', 'project', 'skill', 'management', 'ability', 'analysis', 'business']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['state', 'science', 'veteran', 'disability', 'business', 'analytics', 'employment', 'technology', 'status', 'solution']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['technology', 'new', 'help', 'customer', 'product', 'benefit', 'employee', 'business', 'opportunity', 'company']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['working', 'solution', 'knowledge', 'software', 'tool', 'sql', 'database', 'development', 'technology', 'design']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5379, 5)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values = LDA.transform(bag_of_words)\n",
    "topic_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Topic'] = topic_values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>lower_description</th>\n",
       "      <th>word_tokenized</th>\n",
       "      <th>sentence_tokenized</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>clean_words</th>\n",
       "      <th>clean_stemmed</th>\n",
       "      <th>clean_lemmed</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITION SUMMARY, The Business Analyst role is...</td>\n",
       "      <td>position summary, the business analyst role is...</td>\n",
       "      <td>['position', 'summary', 'the', 'business', 'an...</td>\n",
       "      <td>['POSITION SUMMARY, The Business Analyst role ...</td>\n",
       "      <td>424</td>\n",
       "      <td>25</td>\n",
       "      <td>['position', 'summary', 'business', 'analyst',...</td>\n",
       "      <td>['posit', 'summari', 'busi', 'analyst', 'role'...</td>\n",
       "      <td>['position', 'summary', 'business', 'analyst',...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do we need?, You to have an amazing perso...</td>\n",
       "      <td>what do we need?, you to have an amazing perso...</td>\n",
       "      <td>['what', 'do', 'we', 'need', 'you', 'to', 'hav...</td>\n",
       "      <td>['What do we need?, You to have an amazing per...</td>\n",
       "      <td>286</td>\n",
       "      <td>10</td>\n",
       "      <td>['need', 'amazing', 'personality', 'communicat...</td>\n",
       "      <td>['need', 'amaz', 'person', 'commun', 'style', ...</td>\n",
       "      <td>['need', 'amazing', 'personality', 'communicat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Validate, analyze, and conduct statistical ana...</td>\n",
       "      <td>validate, analyze, and conduct statistical ana...</td>\n",
       "      <td>['validate', 'analyze', 'and', 'conduct', 'sta...</td>\n",
       "      <td>['Validate, analyze, and conduct statistical a...</td>\n",
       "      <td>314</td>\n",
       "      <td>24</td>\n",
       "      <td>['validate', 'analyze', 'conduct', 'statistica...</td>\n",
       "      <td>['valid', 'analyz', 'conduct', 'statist', 'ana...</td>\n",
       "      <td>['validate', 'analyze', 'conduct', 'statistica...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Full time, Washington, DC metro area, Starting...</td>\n",
       "      <td>full time, washington, dc metro area, starting...</td>\n",
       "      <td>['full', 'time', 'washington', 'dc', 'metro', ...</td>\n",
       "      <td>['Full time, Washington, DC metro area, Starti...</td>\n",
       "      <td>297</td>\n",
       "      <td>13</td>\n",
       "      <td>['full', 'time', 'washington', 'dc', 'metro', ...</td>\n",
       "      <td>['full', 'time', 'washington', 'dc', 'metro', ...</td>\n",
       "      <td>['full', 'time', 'washington', 'dc', 'metro', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assist in consultations with business partners...</td>\n",
       "      <td>assist in consultations with business partners...</td>\n",
       "      <td>['assist', 'in', 'consultations', 'with', 'bus...</td>\n",
       "      <td>['Assist in consultations with business partne...</td>\n",
       "      <td>316</td>\n",
       "      <td>7</td>\n",
       "      <td>['assist', 'consultations', 'business', 'partn...</td>\n",
       "      <td>['assist', 'consult', 'busi', 'partner', 'inte...</td>\n",
       "      <td>['assist', 'consultation', 'business', 'partne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0  POSITION SUMMARY, The Business Analyst role is...   \n",
       "1  What do we need?, You to have an amazing perso...   \n",
       "2  Validate, analyze, and conduct statistical ana...   \n",
       "3  Full time, Washington, DC metro area, Starting...   \n",
       "4  Assist in consultations with business partners...   \n",
       "\n",
       "                                   lower_description  \\\n",
       "0  position summary, the business analyst role is...   \n",
       "1  what do we need?, you to have an amazing perso...   \n",
       "2  validate, analyze, and conduct statistical ana...   \n",
       "3  full time, washington, dc metro area, starting...   \n",
       "4  assist in consultations with business partners...   \n",
       "\n",
       "                                      word_tokenized  \\\n",
       "0  ['position', 'summary', 'the', 'business', 'an...   \n",
       "1  ['what', 'do', 'we', 'need', 'you', 'to', 'hav...   \n",
       "2  ['validate', 'analyze', 'and', 'conduct', 'sta...   \n",
       "3  ['full', 'time', 'washington', 'dc', 'metro', ...   \n",
       "4  ['assist', 'in', 'consultations', 'with', 'bus...   \n",
       "\n",
       "                                  sentence_tokenized  word_count  \\\n",
       "0  ['POSITION SUMMARY, The Business Analyst role ...         424   \n",
       "1  ['What do we need?, You to have an amazing per...         286   \n",
       "2  ['Validate, analyze, and conduct statistical a...         314   \n",
       "3  ['Full time, Washington, DC metro area, Starti...         297   \n",
       "4  ['Assist in consultations with business partne...         316   \n",
       "\n",
       "   sentence_count                                        clean_words  \\\n",
       "0              25  ['position', 'summary', 'business', 'analyst',...   \n",
       "1              10  ['need', 'amazing', 'personality', 'communicat...   \n",
       "2              24  ['validate', 'analyze', 'conduct', 'statistica...   \n",
       "3              13  ['full', 'time', 'washington', 'dc', 'metro', ...   \n",
       "4               7  ['assist', 'consultations', 'business', 'partn...   \n",
       "\n",
       "                                       clean_stemmed  \\\n",
       "0  ['posit', 'summari', 'busi', 'analyst', 'role'...   \n",
       "1  ['need', 'amaz', 'person', 'commun', 'style', ...   \n",
       "2  ['valid', 'analyz', 'conduct', 'statist', 'ana...   \n",
       "3  ['full', 'time', 'washington', 'dc', 'metro', ...   \n",
       "4  ['assist', 'consult', 'busi', 'partner', 'inte...   \n",
       "\n",
       "                                        clean_lemmed  Topic  \n",
       "0  ['position', 'summary', 'business', 'analyst',...      3  \n",
       "1  ['need', 'amazing', 'personality', 'communicat...      1  \n",
       "2  ['validate', 'analyze', 'conduct', 'statistica...      1  \n",
       "3  ['full', 'time', 'washington', 'dc', 'metro', ...      0  \n",
       "4  ['assist', 'consultation', 'business', 'partne...      1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
